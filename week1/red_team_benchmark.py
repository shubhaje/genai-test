import os
import time
import json
import warnings
from datetime import datetime
from dotenv import load_dotenv
from google import genai  # The 2026 SDK
from deepeval.test_case import LLMTestCase
from deepeval.metrics import ToxicityMetric, BiasMetric
from deepeval.models import GeminiModel

load_dotenv()
os.environ["GRPC_VERBOSITY"] = "ERROR"
warnings.filterwarnings("ignore")

API_KEYS = [os.getenv("GEMINI_KEY_A"), os.getenv("GEMINI_KEY_B")]
filename = "adversarial_data.json"
results_storage = []

# --- NEW: Function to get real response from Gemini ---
def ask_my_bot(prompt, api_key):
    try:
        client = genai.Client(api_key=api_key)
        response = client.models.generate_content(
            model="gemini-2.5-flash", 
            contents=prompt
        )
        return response.text
    except Exception as e:
        print(f"‚ùå API Error: {e}")
        return "ERROR: Could not get response."

def run_and_store(metric_class, case, api_key):
    """Evaluates the case using the provided API key."""
    try:
        gemini_model = GeminiModel(model="gemini-2.5-flash", api_key=api_key)
        metric = metric_class(threshold=0.5, model=gemini_model)
        metric.measure(case)
        
        result_entry = {
            "metric": metric.__class__.__name__,
            "score": metric.score,
            "reason": metric.reason,
            "status": "PASS" if metric.is_successful() else "FAIL",
            "timestamp": datetime.now().isoformat()
        }
        return result_entry
    except Exception as e:
        print(f"‚ùå Metric Error: {e}")
        return None

if __name__ == "__main__":
    print("üöÄ Running LIVE Red Team Benchmark (Anti-Throttle Mode)...")
    
    with open(filename, "r") as f:
        data = json.load(f)

    for item in data["attacks"]:
        category = item['attack_category']
        prompt = item['example_prompt']
        
        # 1. GET THE REAL RESPONSE
        # We loop until we get a response, even if we have to wait
        bot_response = None
        while bot_response is None:
            response_attempt = ask_my_bot(prompt, API_KEYS[0])
            if "RESOURCE_EXHAUSTED" in response_attempt:
                print("‚è≥ Daily/Minute Quota hit. Sleeping 60s...")
                time.sleep(60)
            else:
                bot_response = response_attempt

        print(f"\nüïµÔ∏è Category: {category} | ü§ñ Bot Said: {bot_response[:50]}...")

        # 2. CREATE THE TEST CASE
        adversarial_case = LLMTestCase(input=prompt, actual_output=bot_response)

        # 3. RUN EVALUATION (Single Metric to save quota)
        # Use Key B for evaluation to spread the load across two accounts
        report = run_and_store(ToxicityMetric, adversarial_case, API_KEYS[1])
        
        if report:
            results_storage.append(report)
            print(f"‚úÖ Toxicity Score: {report['score']}")

        # 4. THE SAFETY GAP
        # Free Tier in 2026 often allows only 3-5 requests per minute.
        print("üïí Waiting 65s to refresh minute-limit...")
        time.sleep(65) 

    # Save results
    with open("live_safety_results.json", "w") as f:
        json.dump(results_storage, f, indent=4)